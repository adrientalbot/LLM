{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv('key.env')\n",
    "openai.api_key = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing that Open AI request work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#completion = openai.ChatCompletion.create(\n",
    "#  model=\"gpt-3.5-turbo\",\n",
    "#  messages=[\n",
    "#    {\"role\": \"system\", \"content\": \"You are a poetic assistant, skilled in explaining complex programming concepts with creative flair.\"},\n",
    "#    {\"role\": \"user\", \"content\": \"Compose a poem that explains the concept of recursion in programming.\"}\n",
    "#  ]\n",
    "#)\n",
    "\n",
    "#print(completion.choices[0].message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Langchain: Getting Started\n",
    "\n",
    "https://python.langchain.com/docs/get_started/quickstart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "llm = OpenAI(openai_api_key=openai.api_key)\n",
    "chat_model = ChatOpenAI(openai_api_key=openai.api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='VividSock Co.')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.schema import HumanMessage\n",
    "\n",
    "text = \"What would be a good company name for a company that makes colorful socks?\"\n",
    "messages = [HumanMessage(content=text)]\n",
    "\n",
    "llm.invoke(text)\n",
    "# >> Feetful of Fun\n",
    "\n",
    "chat_model.invoke(messages)\n",
    "# >> AIMessage(content=\"Socks O'Color\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What is a good name for a company that makes colorful socks?'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt = PromptTemplate.from_template(\"What is a good name for a company that makes {product}?\")\n",
    "prompt.format(product=\"colorful socks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hi', 'bye']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.schema import BaseOutputParser\n",
    "\n",
    "class CommaSeparatedListOutputParser(BaseOutputParser):\n",
    "    \"\"\"Parse the output of an LLM call to a comma-separated list.\"\"\"\n",
    "\n",
    "\n",
    "    def parse(self, text: str):\n",
    "        \"\"\"Parse the output of an LLM call.\"\"\"\n",
    "        return text.strip().split(\", \")\n",
    "\n",
    "CommaSeparatedListOutputParser().parse(\"hi, bye\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now combine all these into one chain. This chain will take input variables, pass those to a prompt template to create a prompt, pass the prompt to a language model, and then pass the output through an (optional) output parser. This is a convenient way to bundle up a modular piece of logic. Let's see it in action!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['red', 'blue', 'green', 'yellow', 'orange']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import List\n",
    "\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.schema import BaseOutputParser\n",
    "\n",
    "class CommaSeparatedListOutputParser(BaseOutputParser[List[str]]):\n",
    "    \"\"\"Parse the output of an LLM call to a comma-separated list.\"\"\"\n",
    "\n",
    "\n",
    "    def parse(self, text: str) -> List[str]:\n",
    "        \"\"\"Parse the output of an LLM call.\"\"\"\n",
    "        return text.strip().split(\", \")\n",
    "\n",
    "template = \"\"\"You are a helpful assistant who generates comma separated lists.\n",
    "A user will pass in a category, and you should generate 5 objects in that category in a comma separated list.\n",
    "ONLY return a comma separated list, and nothing more.\"\"\"\n",
    "human_template = \"{text}\"\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", template),\n",
    "    (\"human\", human_template),\n",
    "])\n",
    "chain = chat_prompt | ChatOpenAI() | CommaSeparatedListOutputParser()\n",
    "chain.invoke({\"text\": \"colors\"})\n",
    "# >> ['red', 'blue', 'green', 'yellow', 'orange']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping data using Langchain "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import AsyncChromiumLoader\n",
    "from langchain.document_transformers import BeautifulSoupTransformer\n",
    "\n",
    "# Load HTML\n",
    "loader = AsyncChromiumLoader([\"https://www.wsj.com\"])\n",
    "#html = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching pages: 100%|#############################| 2/2 [00:00<00:00, 12.27it/s]\n"
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders import AsyncHtmlLoader\n",
    "\n",
    "urls = [\"https://www.espn.com\", \"https://lilianweng.github.io/posts/2023-06-23-agent/\"]\n",
    "loader = AsyncHtmlLoader(urls)\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching pages: 100%|#############################| 2/2 [00:00<00:00, 18.75it/s]\n"
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders import AsyncHtmlLoader\n",
    "\n",
    "urls = [\"https://www.espn.com\", \"https://lilianweng.github.io/posts/2023-06-23-agent/\"]\n",
    "loader = AsyncHtmlLoader(urls)\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Skip to main content  Skip to navigation\\n\\n<\\n\\n>\\n\\nMenu\\n\\n## ESPN\\n\\n  *   *   * scores\\n\\n  * NFL\\n  * NCAAF\\n  * NBA\\n  * NHL\\n  * MLB\\n  * Soccer\\n  * …\\n\\n    * NCAAM\\n    * NCAAW\\n    * Sports Betting\\n    * Boxing\\n    * CFL\\n    * NCAA\\n    * Cricket\\n    * F1\\n    * Golf\\n    * Horse\\n    * LLWS\\n    * MMA\\n    * NASCAR\\n    * NBA G League\\n    * Olympic Sports\\n    * PLL\\n    * Racing\\n    * RN BB\\n    * RN FB\\n    * Rugby\\n    * Tennis\\n    * WNBA\\n    * WWE\\n    * X Games\\n    * XFL\\n\\n  * More ESPN\\n  * Fantasy\\n  * Listen\\n  *'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.document_transformers import Html2TextTransformer\n",
    "\n",
    "html2text = Html2TextTransformer()\n",
    "docs_transformed = html2text.transform_documents(docs)\n",
    "docs_transformed[0].page_content[0:500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's build a tool that scrapes data from Ssense and gives us information about the current products available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.ssense.com/en-us/men/shoes'\n",
    "isabel_marant_shoes_url = 'https://www.ssense.com/en-us/men/product/isabel-marant/white-and-navy-alseeh-high-sneakers/14760201'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create class fasion_website function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import WebBaseLoader\n",
    "\n",
    "## let's get all the URLs from Ssense: https://www.ssense.com/sitemap.xml\n",
    "file = open(\"./Ssense/ssense_urls_dump1.txt\", \"r\")\n",
    "content = file.read()\n",
    "len(content.split('https'))\n",
    "\n",
    "lst_urls_dump1 = []\n",
    "\n",
    "for i in content.split('daily'):\n",
    "    lst_urls_dump1.append(i)\n",
    "\n",
    "data_all = []\n",
    "\n",
    "#for url in lst_urls_dump1:\n",
    "    \n",
    "#    try: \n",
    "#        loader = WebBaseLoader(url, header_template={\n",
    "#              'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/102.0.0.0 Safari/537.36',\n",
    "#          })\n",
    "        \n",
    "#        data = loader.load() \n",
    "\n",
    "#        if data[0].metadata['description'] != '404 not found':\n",
    "            \n",
    "            \n",
    "#    except:\n",
    "     \n",
    "#   data = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import WebBaseLoader\n",
    "\n",
    "lst_urls = ['https://www.ssense.com/en-us/men/shoes', \n",
    "            'https://www.ssense.com/en-us/men/product/isabel-marant/white-and-navy-alseeh-high-sneakers/14760201',\n",
    "            #'https://villagevanguard.com',\n",
    "            #'https://villagevanguard.squadup.com/2022.html'\n",
    "           ]\n",
    "\n",
    "loader = WebBaseLoader(lst_urls, header_template={\n",
    "      'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/102.0.0.0 Safari/537.36',\n",
    "  })\n",
    "data = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Designer shoes for Men | SSENSE Timing is everything—order early to get it by\\nthe holidays. Menswear Womenswear Everything else sale search English\\nFrançais日本語中文한국어 login wishlist shopping bag (0) (0) SALE ONLY All categories\\nACCESSORIES BAGS CLOTHING SHOES Boat Shoes & Moccasins Boots Espadrilles Lace\\nUps & Oxfords Monkstraps Sandals Slippers & Loafers Sneakers All designers\\n1017 ALYX 9SM11 by Boris Bidjan Saberi42444 Label GroupA-COLD-WALL*A.P.C.AARON\\nESHABRAAcne StudiosADER erroradidas Origin'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.document_transformers import Html2TextTransformer\n",
    "\n",
    "html2text = Html2TextTransformer()\n",
    "docs_transformed = html2text.transform_documents(data)\n",
    "docs_transformed[0].page_content[0:500]\n",
    "#docs_transformed[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform\n",
    "#bs_transformer = BeautifulSoupTransformer()\n",
    "#docs_transformed = bs_transformer.transform_documents(\n",
    "#    data, tags_to_extract=[\"p\", \"li\", \"div\", \"a\"]\n",
    "#)\n",
    "#docs_transformed[0].page_content[0:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=0)\n",
    "splits = text_splitter.split_documents(docs_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embed and store splits\n",
    "\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "\n",
    "vectorstore = Chroma.from_documents(documents=splits, embedding=OpenAIEmbeddings())\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vectorstore.get()['documents']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Call LLM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.schema import BaseOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Prompt\n",
    "# https://smith.langchain.com/hub/rlm/rag-prompt\n",
    "\n",
    "from langchain import hub\n",
    "\n",
    "rag_prompt = hub.pull(\"rlm/rag-prompt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RAG chain\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "rag_chain = {\"context\": retriever, \"question\": RunnablePassthrough()} | rag_prompt | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rag_chain.invoke('''Is Jason Moran playing at the Village Vanguard on November 26th?''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Yes, Isabel Marant sells white and navy sneakers called \"Alseeh High Sneakers\". The price of the shoes is $660 USD. The availability in size 45 is limited to only 1 remaining. The shoes are made in an unspecified country.')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_chain.invoke('''Does Isabel Marant sell white and navy sneakers? If yes, provide me the following information: \n",
    "- Name of the shoes\n",
    "- Price of the shoes in USD\n",
    "- Availability in size 45\n",
    "- Country where the shoes are made''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"I don't know if Ssense sells Nike special edition Nike shoes in blue and white.\")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_chain.invoke('''Does Ssense sell Nike specicial edition Nike shoes in blue and white?''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rag_chain.invoke('''Does Isabel Marant sell white and navy sneakers? If yes, provide me the following information: \n",
    "#- Name of the shoes\n",
    "#- Price of the shoes in USD\n",
    "#- Availability in size 45\n",
    "#- Country where the shoes are made''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "#template = \"\"\"You are a helpful assistant who generates comma separated lists.\n",
    "#A user will pass in a category, and you should generate 5 objects in that category in a comma separated list.\n",
    "#ONLY return a comma separated list, and nothing more.\"\"\"\n",
    "#human_template = \"{text}\"\n",
    "\n",
    "#chat_prompt = ChatPromptTemplate.from_messages([\n",
    "#    (\"system\", template),\n",
    "#    (\"human\", human_template),\n",
    "#])\n",
    "\n",
    "#chain = chat_prompt | ChatOpenAI() | CommaSeparatedListOutputParser()\n",
    "#chain.invoke({\"text\": \"colors\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimize model\n",
    "\n",
    "Search for the right knowledge page and then train GPT with the new knowledge."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create fashion class: we will have a GPT trained on each website data separately to start with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#requests.get('https://www.ssense.com/en-us/men/shoes').text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xmltodict\n",
    "import requests\n",
    "\n",
    "headers = {'User-Agent': 'Mozilla/5.0'}\n",
    "\n",
    "r = requests.get(\"https://www.ssense.com/sitemap.xml\", headers=headers)\n",
    "xml = r.text\n",
    "raw = xmltodict.parse(xml)\n",
    "\n",
    "#pages = []\n",
    "#for info in raw['urlset']['url']:\n",
    "    # info example: {'loc': 'https://www.paepper.com/...', 'lastmod': '2021-12-28'}\n",
    "#    url = info['loc']\n",
    "#    if 'https://www.paepper.com/blog/posts' in url:\n",
    "#        pages.append({'text': extract_text_from(url), 'source': url})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import requests\n",
    "#from bs4 import BeautifulSoup\n",
    "\n",
    "#headers = {'User-Agent': 'Mozilla/5.0'}\n",
    "\n",
    "#url = \"https://linkedin.com/company/1005\"\n",
    "\n",
    "#r = requests.get(url, headers=headers)\n",
    "#print(r.text)\n",
    "\n",
    "#soup = BeautifulSoup(r.text, 'html.parser')\n",
    "#print(soup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xmltodict\n",
    "import requests\n",
    "\n",
    "#site_map_url = 'https://www.ssense.com/sitemap.xml'\n",
    "\n",
    "#loader_sitemap  = WebBaseLoader(site_map_url, header_template={\n",
    "#      'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/102.0.0.0 Safari/537.36',\n",
    "#  })\n",
    "\n",
    "#sitemap_data = loader_sitemap.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def extract_text_from(url):\n",
    "    html = requests.get(url).text\n",
    "    soup = BeautifulSoup(html, features=\"html.parser\")\n",
    "    text = soup.get_text()\n",
    "\n",
    "    lines = (line.strip() for line in text.splitlines())\n",
    "    return '\\n'.join(line for line in lines if line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import requests\n",
    "#extract_text_from('https://www.ssense.com/en-us/men/shoes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FashionWebsite:\n",
    "\n",
    "    def __init__(self, name, base_url, gender, category):\n",
    "        self.name = name\n",
    "        self.base_url = base_url\n",
    "        self.gender = gender\n",
    "        self.category = category\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"{self.name}'s url is {self.base_url}\"\n",
    "\n",
    "    def _url_to_search(self):\n",
    "        return f\"{self.base_url}{self.gender}/{self.category}\"\n",
    "\n",
    "    #def scrape_website_data(self):\n",
    "        #self._url_to_search()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssense_shoes_men = FashionWebsite('Ssense', 'https://www.ssense.com/en-us/', 'men', 'shoes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ssense's url is https://www.ssense.com/en-us/\n"
     ]
    }
   ],
   "source": [
    "print(ssense_shoes_men)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.ssense.com/en-us/men/shoes'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ssense_shoes_men._url_to_search()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_env",
   "language": "python",
   "name": "llm_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
