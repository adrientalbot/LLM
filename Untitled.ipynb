{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv('key.env')\n",
    "openai.api_key = os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing that Open AI request work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#completion = openai.ChatCompletion.create(\n",
    "#  model=\"gpt-3.5-turbo\",\n",
    "#  messages=[\n",
    "#    {\"role\": \"system\", \"content\": \"You are a poetic assistant, skilled in explaining complex programming concepts with creative flair.\"},\n",
    "#    {\"role\": \"user\", \"content\": \"Compose a poem that explains the concept of recursion in programming.\"}\n",
    "#  ]\n",
    "#)\n",
    "\n",
    "#print(completion.choices[0].message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Langchain: Getting Started\n",
    "\n",
    "https://python.langchain.com/docs/get_started/quickstart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "llm = OpenAI(openai_api_key=openai.api_key)\n",
    "chat_model = ChatOpenAI(openai_api_key=openai.api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='VividSock Co.')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.schema import HumanMessage\n",
    "\n",
    "text = \"What would be a good company name for a company that makes colorful socks?\"\n",
    "messages = [HumanMessage(content=text)]\n",
    "\n",
    "llm.invoke(text)\n",
    "# >> Feetful of Fun\n",
    "\n",
    "chat_model.invoke(messages)\n",
    "# >> AIMessage(content=\"Socks O'Color\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What is a good name for a company that makes colorful socks?'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt = PromptTemplate.from_template(\"What is a good name for a company that makes {product}?\")\n",
    "prompt.format(product=\"colorful socks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hi', 'bye']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.schema import BaseOutputParser\n",
    "\n",
    "class CommaSeparatedListOutputParser(BaseOutputParser):\n",
    "    \"\"\"Parse the output of an LLM call to a comma-separated list.\"\"\"\n",
    "\n",
    "\n",
    "    def parse(self, text: str):\n",
    "        \"\"\"Parse the output of an LLM call.\"\"\"\n",
    "        return text.strip().split(\", \")\n",
    "\n",
    "CommaSeparatedListOutputParser().parse(\"hi, bye\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now combine all these into one chain. This chain will take input variables, pass those to a prompt template to create a prompt, pass the prompt to a language model, and then pass the output through an (optional) output parser. This is a convenient way to bundle up a modular piece of logic. Let's see it in action!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['red', 'blue', 'green', 'yellow', 'orange']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import List\n",
    "\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.schema import BaseOutputParser\n",
    "\n",
    "class CommaSeparatedListOutputParser(BaseOutputParser[List[str]]):\n",
    "    \"\"\"Parse the output of an LLM call to a comma-separated list.\"\"\"\n",
    "\n",
    "\n",
    "    def parse(self, text: str) -> List[str]:\n",
    "        \"\"\"Parse the output of an LLM call.\"\"\"\n",
    "        return text.strip().split(\", \")\n",
    "\n",
    "template = \"\"\"You are a helpful assistant who generates comma separated lists.\n",
    "A user will pass in a category, and you should generate 5 objects in that category in a comma separated list.\n",
    "ONLY return a comma separated list, and nothing more.\"\"\"\n",
    "human_template = \"{text}\"\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", template),\n",
    "    (\"human\", human_template),\n",
    "])\n",
    "chain = chat_prompt | ChatOpenAI() | CommaSeparatedListOutputParser()\n",
    "chain.invoke({\"text\": \"colors\"})\n",
    "# >> ['red', 'blue', 'green', 'yellow', 'orange']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scraping data using Langchain "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import AsyncChromiumLoader\n",
    "from langchain.document_transformers import BeautifulSoupTransformer\n",
    "\n",
    "# Load HTML\n",
    "loader = AsyncChromiumLoader([\"https://www.wsj.com\"])\n",
    "#html = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching pages: 100%|#############################| 2/2 [00:00<00:00, 12.27it/s]\n"
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders import AsyncHtmlLoader\n",
    "\n",
    "urls = [\"https://www.espn.com\", \"https://lilianweng.github.io/posts/2023-06-23-agent/\"]\n",
    "loader = AsyncHtmlLoader(urls)\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching pages: 100%|#############################| 2/2 [00:00<00:00, 18.75it/s]\n"
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders import AsyncHtmlLoader\n",
    "\n",
    "urls = [\"https://www.espn.com\", \"https://lilianweng.github.io/posts/2023-06-23-agent/\"]\n",
    "loader = AsyncHtmlLoader(urls)\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Skip to main content  Skip to navigation\\n\\n<\\n\\n>\\n\\nMenu\\n\\n## ESPN\\n\\n  *   *   * scores\\n\\n  * NFL\\n  * NCAAF\\n  * NBA\\n  * NHL\\n  * MLB\\n  * Soccer\\n  * â€¦\\n\\n    * NCAAM\\n    * NCAAW\\n    * Sports Betting\\n    * Boxing\\n    * CFL\\n    * NCAA\\n    * Cricket\\n    * F1\\n    * Golf\\n    * Horse\\n    * LLWS\\n    * MMA\\n    * NASCAR\\n    * NBA G League\\n    * Olympic Sports\\n    * PLL\\n    * Racing\\n    * RN BB\\n    * RN FB\\n    * Rugby\\n    * Tennis\\n    * WNBA\\n    * WWE\\n    * X Games\\n    * XFL\\n\\n  * More ESPN\\n  * Fantasy\\n  * Listen\\n  *'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.document_transformers import Html2TextTransformer\n",
    "\n",
    "html2text = Html2TextTransformer()\n",
    "docs_transformed = html2text.transform_documents(docs)\n",
    "docs_transformed[0].page_content[0:500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's build a tool that scrapes data from Ssense and gives us information about the current products available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.ssense.com/en-us/men/shoes'\n",
    "isabel_marant_shoes_url = 'https://www.ssense.com/en-us/men/product/isabel-marant/white-and-navy-alseeh-high-sneakers/14760201'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create class fasion_website function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import WebBaseLoader\n",
    "\n",
    "## let's get all the URLs from Ssense: https://www.ssense.com/sitemap.xml\n",
    "file = open(\"./Ssense/ssense_urls_dump1.txt\", \"r\")\n",
    "content = file.read()\n",
    "len(content.split('https'))\n",
    "\n",
    "lst_urls_dump1 = []\n",
    "\n",
    "for i in content.split('daily'):\n",
    "    lst_urls_dump1.append(i)\n",
    "\n",
    "data_all = []\n",
    "\n",
    "#for url in lst_urls_dump1:\n",
    "    \n",
    "#    try: \n",
    "#        loader = WebBaseLoader(url, header_template={\n",
    "#              'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/102.0.0.0 Safari/537.36',\n",
    "#          })\n",
    "        \n",
    "#        data = loader.load() \n",
    "\n",
    "#        if data[0].metadata['description'] != '404 not found':\n",
    "            \n",
    "            \n",
    "#    except:\n",
    "     \n",
    "#   data = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import WebBaseLoader\n",
    "\n",
    "lst_urls = ['https://www.ssense.com/en-us/men/shoes', \n",
    "            'https://www.ssense.com/en-us/men/product/isabel-marant/white-and-navy-alseeh-high-sneakers/14760201',\n",
    "            #'https://villagevanguard.com',\n",
    "            #'https://villagevanguard.squadup.com/2022.html'\n",
    "           ]\n",
    "\n",
    "loader = WebBaseLoader(lst_urls, header_template={\n",
    "      'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/102.0.0.0 Safari/537.36',\n",
    "  })\n",
    "data = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Designer shoes for Men | SSENSE Timing is everythingâ€”order early to get it by\\nthe holidays. Menswear Womenswear Everything else sale search English\\nFranÃ§aisæ—¥æœ¬èªžä¸­æ–‡í•œêµ­ì–´ login wishlist shopping bag (0) (0) SALE ONLY All categories\\nACCESSORIES BAGS CLOTHING SHOES Boat Shoes & Moccasins Boots Espadrilles Lace\\nUps & Oxfords Monkstraps Sandals Slippers & Loafers Sneakers All designers\\n1017 ALYX 9SM11 by Boris Bidjan Saberi42444 Label GroupA-COLD-WALL*A.P.C.AARON\\nESHABRAAcne StudiosADER erroradidas Origin'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.document_transformers import Html2TextTransformer\n",
    "\n",
    "html2text = Html2TextTransformer()\n",
    "docs_transformed = html2text.transform_documents(data)\n",
    "docs_transformed[0].page_content[0:500]\n",
    "#docs_transformed[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform\n",
    "#bs_transformer = BeautifulSoupTransformer()\n",
    "#docs_transformed = bs_transformer.transform_documents(\n",
    "#    data, tags_to_extract=[\"p\", \"li\", \"div\", \"a\"]\n",
    "#)\n",
    "#docs_transformed[0].page_content[0:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=0)\n",
    "splits = text_splitter.split_documents(docs_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embed and store splits\n",
    "\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "\n",
    "vectorstore = Chroma.from_documents(documents=splits, embedding=OpenAIEmbeddings())\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vectorstore.get()['documents']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Call LLM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.schema import BaseOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Prompt\n",
    "# https://smith.langchain.com/hub/rlm/rag-prompt\n",
    "\n",
    "from langchain import hub\n",
    "\n",
    "rag_prompt = hub.pull(\"rlm/rag-prompt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RAG chain\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "rag_chain = {\"context\": retriever, \"question\": RunnablePassthrough()} | rag_prompt | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rag_chain.invoke('''Is Jason Moran playing at the Village Vanguard on November 26th?''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Yes, Isabel Marant sells white and navy sneakers called \"Alseeh High Sneakers\". The price of the shoes is $660 USD. The availability in size 45 is limited to only 1 remaining. The shoes are made in an unspecified country.')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_chain.invoke('''Does Isabel Marant sell white and navy sneakers? If yes, provide me the following information: \n",
    "- Name of the shoes\n",
    "- Price of the shoes in USD\n",
    "- Availability in size 45\n",
    "- Country where the shoes are made''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"I don't know if Ssense sells Nike special edition Nike shoes in blue and white.\")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_chain.invoke('''Does Ssense sell Nike specicial edition Nike shoes in blue and white?''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rag_chain.invoke('''Does Isabel Marant sell white and navy sneakers? If yes, provide me the following information: \n",
    "#- Name of the shoes\n",
    "#- Price of the shoes in USD\n",
    "#- Availability in size 45\n",
    "#- Country where the shoes are made''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "#template = \"\"\"You are a helpful assistant who generates comma separated lists.\n",
    "#A user will pass in a category, and you should generate 5 objects in that category in a comma separated list.\n",
    "#ONLY return a comma separated list, and nothing more.\"\"\"\n",
    "#human_template = \"{text}\"\n",
    "\n",
    "#chat_prompt = ChatPromptTemplate.from_messages([\n",
    "#    (\"system\", template),\n",
    "#    (\"human\", human_template),\n",
    "#])\n",
    "\n",
    "#chain = chat_prompt | ChatOpenAI() | CommaSeparatedListOutputParser()\n",
    "#chain.invoke({\"text\": \"colors\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimize model\n",
    "\n",
    "Search for the right knowledge page and then train GPT with the new knowledge."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create fashion class: we will have a GPT trained on each website data separately to start with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#requests.get('https://www.ssense.com/en-us/men/shoes').text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xmltodict\n",
    "import requests\n",
    "\n",
    "headers = {'User-Agent': 'Mozilla/5.0'}\n",
    "\n",
    "r = requests.get(\"https://www.ssense.com/sitemap.xml\", headers=headers)\n",
    "xml = r.text\n",
    "raw = xmltodict.parse(xml)\n",
    "\n",
    "#pages = []\n",
    "#for info in raw['urlset']['url']:\n",
    "    # info example: {'loc': 'https://www.paepper.com/...', 'lastmod': '2021-12-28'}\n",
    "#    url = info['loc']\n",
    "#    if 'https://www.paepper.com/blog/posts' in url:\n",
    "#        pages.append({'text': extract_text_from(url), 'source': url})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import requests\n",
    "#from bs4 import BeautifulSoup\n",
    "\n",
    "#headers = {'User-Agent': 'Mozilla/5.0'}\n",
    "\n",
    "#url = \"https://linkedin.com/company/1005\"\n",
    "\n",
    "#r = requests.get(url, headers=headers)\n",
    "#print(r.text)\n",
    "\n",
    "#soup = BeautifulSoup(r.text, 'html.parser')\n",
    "#print(soup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xmltodict\n",
    "import requests\n",
    "\n",
    "#site_map_url = 'https://www.ssense.com/sitemap.xml'\n",
    "\n",
    "#loader_sitemap  = WebBaseLoader(site_map_url, header_template={\n",
    "#      'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/102.0.0.0 Safari/537.36',\n",
    "#  })\n",
    "\n",
    "#sitemap_data = loader_sitemap.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def extract_text_from(url):\n",
    "    html = requests.get(url).text\n",
    "    soup = BeautifulSoup(html, features=\"html.parser\")\n",
    "    text = soup.get_text()\n",
    "\n",
    "    lines = (line.strip() for line in text.splitlines())\n",
    "    return '\\n'.join(line for line in lines if line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import requests\n",
    "#extract_text_from('https://www.ssense.com/en-us/men/shoes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FashionWebsite:\n",
    "\n",
    "    def __init__(self, name, base_url, gender, category):\n",
    "        self.name = name\n",
    "        self.base_url = base_url\n",
    "        self.gender = gender\n",
    "        self.category = category\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"{self.name}'s url is {self.base_url}\"\n",
    "\n",
    "    def _url_to_search(self):\n",
    "        return f\"{self.base_url}{self.gender}/{self.category}\"\n",
    "\n",
    "    #def scrape_website_data(self):\n",
    "        #self._url_to_search()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssense_shoes_men = FashionWebsite('Ssense', 'https://www.ssense.com/en-us/', 'men', 'shoes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ssense's url is https://www.ssense.com/en-us/\n"
     ]
    }
   ],
   "source": [
    "print(ssense_shoes_men)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://www.ssense.com/en-us/men/shoes'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ssense_shoes_men._url_to_search()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_env",
   "language": "python",
   "name": "llm_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
